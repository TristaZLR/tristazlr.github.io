{"title":"Data Analysis with Python 3","date":"2019-05-10T04:12:32.000Z","thumbnail":"https://i.postimg.cc/WpdV78bX/3-phases-of-data-analysis-b.jpg","slug":"Data Analysis with Python 3","tags":["Data Science","python"],"categories":["学习 - DA"],"updated":"2019-05-16T04:22:28.054Z","content":"<h1 id=\"Data-Analysis-with-Python-3\"><center>Data Analysis with Python 3</center><a href=\"post/Data Analysis with Python 3#Data-Analysis-with-Python-3\"></a></h1><h2 id=\"Model-Evaluation\">Model Evaluation<a href=\"post/Data Analysis with Python 3#Model-Evaluation\"></a></h2><h3 id=\"Model-Evaluation-1\">Model Evaluation<a href=\"post/Data Analysis with Python 3#Model-Evaluation-1\"></a></h3><p>首先对于in-sample和out-sample的定义可以参考如下：<br><a href=\"https://stats.stackexchange.com/questions/260899/what-is-difference-between-in-sample-and-out-of-sample-forecasts\" target=\"_blank\" rel=\"noopener\">What is difference between “in-sample” and “out-of-sample” forecasts?</a><br>in-sample的评估并不能判断数据预测的准确性<br>解决办法：使用train_test_spilt()随机分配训练数据&amp;测试数据<br><code>from sklearn.model_selection import train_test_spilt</code><br><code>x_train,x_test,y_train,y_test = train_test_spilt(x_data,y_data,test_size=0.3,random_state=0)</code></p>\n<p>泛化误差（Generalization Error）<br>模型在总体上的误差<br>应对方法：cross vaildation交叉验证，把数据分成n份，每部分轮流做testset<br><code>from sklearn.model_selection import cross_val_score</code><br><code>scores = cross_val_score(lr,x_data,y_data,cv=3)//lr是模型类型</code><br><code>np.mean(scores)</code><br><code>from sklearn.model_selection import cross_val_predict</code><br><code>yhat = cross_val_predict(lr2e,x_data,y_data,cv=3)</code>  </p>\n<h3 id=\"Overfitting-Underfitting-and-Model-Selection\">Overfitting, Underfitting and Model Selection<a href=\"post/Data Analysis with Python 3#Overfitting-Underfitting-and-Model-Selection\"></a></h3><p>关键点在于如何选择多项回归的阶数  </p>\n<ul>\n<li><p>当模型远远不满足数据时叫做under_fitting</p>\n</li>\n<li><p>当模型过于跟随noise时叫做over_fitting  </p>\n</li>\n</ul>\n<p>可以用R<sup>2</sup>来检查是否为最佳阶数，R<sup>2</sup>越接近1，越准确<br><code>order=[1,2,3,4]</code><br><code>for n in order</code><br><code>pr=PolynomialFeatures(degree=n)</code><br><code>x_train_pr=pr.fit_transform(x_train[[&#39;***&#39;]])</code><br><code>x_test_pr=pr.fit_transform(x_teset[[&#39;***&#39;]])</code><br><code>lr.fit(x_train_pr,y_train)</code><br><code>Rsqu_test.append(lr.score(x_test_pr,y_test))</code></p>\n<h3 id=\"Ridge-Regression-岭回归\">Ridge Regression 岭回归<a href=\"post/Data Analysis with Python 3#Ridge-Regression-岭回归\"></a></h3><p>可以用来控制高阶变量的系数<br><code>from sklearn.linear_model import Ridge</code><br><code>RigeModel=Ridge(alpha=0.1)</code><br><code>RigeModel.fit(X,y)</code><br><code>Yhat=RigeModel.predict(X)</code></p>\n<h3 id=\"Grid-Search\">Grid Search<a href=\"post/Data Analysis with Python 3#Grid-Search\"></a></h3><p>scikit-learn能自动迭代超参数（Alpha）通过使用交叉验证的网络搜索<br>需要将Data分成三部分</p>\n<ol>\n<li>Training   ——&gt;对不同超参数训练模型</li>\n<li>Vaildation ——&gt;选出让mean<sup>2</sup>最小或R<sup>2</sup>最大的超参</li>\n<li>Test       ——&gt; 测试模型的好坏  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parameters = [&#123;&apos;alpha&apos;:[1,10,100,1000]&#125;]  //dictionary</span><br><span class=\"line\">from sklearn.linear_model import Ridge</span><br><span class=\"line\">from sklearn.model_selection import GridSearchCV</span><br><span class=\"line\">parameters1=[&#123;&apos;alpha&apos;:[0.001,0.1,1,10,100,1000,10000,100000,1000000]&#125;]</span><br><span class=\"line\">RR=Ridge</span><br><span class=\"line\">Grid1.fit(x_data[[&apos;***&apos;,&apos;***&apos;,&apos;***&apos;,&apos;***&apos;]],y_data)</span><br><span class=\"line\">Grid1.best_estimator_   //找到最佳参数</span><br><span class=\"line\">scores=Grid1.cv_results_</span><br><span class=\"line\">scores[&apos;mean_test_score&apos;]</span><br></pre></td></tr></table></figure></li>\n</ol>\n","prev":{"title":"Data Analysis with Python 2","slug":"Data Analysis with Python 2"},"next":{"title":"My Life.md","slug":"My Life"},"link":"https://www.tristazlr.top/post/Data Analysis with Python 3/","toc":[{"title":"<center>Data Analysis with Python 3</center>","id":"Data-Analysis-with-Python-3","index":"1","children":[{"title":"Model Evaluation","id":"Model-Evaluation","index":"1.1","children":[{"title":"Model Evaluation","id":"Model-Evaluation-1","index":"1.1.1"},{"title":"Overfitting, Underfitting and Model Selection","id":"Overfitting-Underfitting-and-Model-Selection","index":"1.1.2"},{"title":"Ridge Regression 岭回归","id":"Ridge-Regression-岭回归","index":"1.1.3"},{"title":"Grid Search","id":"Grid-Search","index":"1.1.4"}]}]}],"copyright":{"author":"Trista's Blog","link":"<a href=\"https://www.tristazlr.top/post/Data Analysis with Python 3/\" title=\"Data Analysis with Python 3\">https://www.tristazlr.top/post/Data Analysis with Python 3/</a>","license":"Attribution-NonCommercial-NoDerivatives 4.0 International (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}